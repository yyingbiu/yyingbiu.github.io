<!DOCTYPE HTML>
<html lang="zh-CN">


<head><meta name="generator" content="Hexo 3.9.0">
    <meta charset="utf-8">
    <meta name="keywords" content="pytorch2onnx, 计算机视觉  深度学习">
    <meta name="baidu-site-verification" content>
    <meta name="google-site-verification" content>
    <meta name="description" content="pytorch2onnx最近做的项目需要把训练好的模型移植到移动端，安卓手机上，实验室选择了ncnn这个框架，所以我选择了pytoch2onnx2ncnn框架的这个思路。下面主要是记录一下pytorch转onnx模型的步骤和踩过的坑。
项目">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <title>pytorch2onnx | ivory&#39;s blog</title>
    <link rel="icon" type="image/png" href="/favicon.png">

    <link rel="stylesheet" type="text/css" href="/libs/awesome/css/font-awesome.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
    <link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
    <link rel="stylesheet" type="text/css" href="/css/matery.css">
    <link rel="stylesheet" type="text/css" href="/css/my.css">
    <style type="text/css">
        
    </style>

    <script src="/libs/jquery/jquery-2.2.0.min.js"></script>
    <script src="https://sdk.jinrishici.com/v2/browser/jinrishici.js" charset="utf-8"></script>
    <script>
        var _hmt = _hmt || [];
        (function () {
            var hm = document.createElement("script");
            hm.src = "https://hm.baidu.com/hm.js?46e79e71af0709a5b9106bf20cecc493";
            var s = document.getElementsByTagName("script")[0];
            s.parentNode.insertBefore(hm, s);
        })();
    </script>
<link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css">
<link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"></head>

<body>

<header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/medias/logo.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">ivory's blog</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fa fa-navicon"></i></a>
<ul class="right">
    
    <li class="hide-on-med-and-down">
        <a href="/" class="waves-effect waves-light">
            
            <span>首页</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/tags" class="waves-effect waves-light">
            
            <span>标签</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/categories" class="waves-effect waves-light">
            
            <span>分类</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/archives" class="waves-effect waves-light">
            
            <span>归档</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/about" class="waves-effect waves-light">
            
            <span>关于</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/friends" class="waves-effect waves-light">
            
            <span>友情链接</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/contact" class="waves-effect waves-light">
            
            <span>留言板</span>
        </a>
    </li>
    
    <li>
        <a href="#searchModal" class="modal-trigger waves-effect waves-light">
            <i id="searchIcon" class="fa fa-search" title="搜索"></i>
        </a>
    </li>
</ul>

<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">ivory's blog</div>
        <div class="logo-desc">
            
            zju  cv
            
        </div>
    </div>

    

    <ul class="menu-list mobile-menu-list">
        
        <li>
            <a href="/" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-link"></i>
                
                首页
            </a>
        </li>
        
        <li>
            <a href="/tags" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-link"></i>
                
                标签
            </a>
        </li>
        
        <li>
            <a href="/categories" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-link"></i>
                
                分类
            </a>
        </li>
        
        <li>
            <a href="/archives" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-link"></i>
                
                归档
            </a>
        </li>
        
        <li>
            <a href="/about" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-link"></i>
                
                关于
            </a>
        </li>
        
        <li>
            <a href="/friends" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-link"></i>
                
                友情链接
            </a>
        </li>
        
        <li>
            <a href="/contact" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-link"></i>
                
                留言板
            </a>
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/yyingbiu" class="waves-effect waves-light" target="_blank">
                <i class="fa fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>

        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/yyingbiu" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>


<script src="/libs/cryptojs/crypto-js.min.js"></script>
<script>
    (function() {
        let pwd = '';
        if (pwd && pwd.length > 0) {
            if (pwd !== CryptoJS.SHA256(prompt('请输入访问本文章的密码')).toString(CryptoJS.enc.Hex)) {
                alert('密码错误，将返回主页！');
                location.href = '/';
            }
        }
    })();
</script>




<div class="bg-cover pd-header post-cover" style="background-image: url('/medias/featureimages/0.png')">
    <div class="container">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <div class="description center-align post-title">
                        pytorch2onnx
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>



<main class="post-container content">

    
    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
<style>
    #articleContent h1::before,
    #articleContent h2::before,
    #articleContent h3::before,
    #articleContent h4::before,
    #articleContent h5::before,
    #articleContent h6::before {
        display: block;
        content: " ";
        height: 100px;
        margin-top: -100px;
        visibility: hidden;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }

    .toc-widget {
        padding-left: 20px;
    }

    .toc-widget .toc-title {
        margin: 35px 0 15px 0;
        padding-left: 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content ol {
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }

    #toc-content .toc-link:hover {
        color: #42b983;
        font-weight: 700;
        text-decoration: underline;
    }

    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;
    }

    #toc-content .is-active-link {
        color: #42b983;
    }

    #toc-content .is-active-link::before {
        background-color: #42b983;
    }

    #floating-toc-btn {
        position: fixed;
        right: 20px;
        bottom: 76px;
        padding-top: 15px;
        margin-bottom: 0;
        z-index: 998;
    }

    #floating-toc-btn .btn-floating {
        width: 48px;
        height: 48px;
    }

    #floating-toc-btn .btn-floating i {
        line-height: 48px;
        font-size: 1.4rem;
    }
</style>
<div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                        <a href="/tags/onnx/" target="_blank">
                            <span class="chip bg-color">onnx</span>
                        </a>
                        
                        <a href="/tags/ncnn/" target="_blank">
                            <span class="chip bg-color">ncnn</span>
                        </a>
                        
                        <a href="/tags/pytorch/" target="_blank">
                            <span class="chip bg-color">pytorch</span>
                        </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fa fa-bookmark fa-fw icon-category"></i>
                        
                        <a href="/categories/深度学习框架/" class="post-category" target="_blank">
                            深度学习框架
                        </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                <div class="post-date info-break-policy">
                    <i class="fa fa-calendar-minus-o fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2019-09-09
                </div>

                <div class="post-author info-break-policy">
                    <i class="fa fa-user-o fa-fw"></i>作者:&nbsp;&nbsp;
                    
                    ivory
                    
                </div>

                
                
                <div class="info-break-policy">
                    <i class="fa fa-file-word-o fa-fw"></i>文章字数:&nbsp;&nbsp;
                    2.9k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="fa fa-clock-o fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    14 分
                </div>
                
                

                
            </div>
        </div>
        <hr class="clearfix">
        <div class="card-content article-card-content">
            <div id="articleContent">
                <h1 id="pytorch2onnx"><a href="#pytorch2onnx" class="headerlink" title="pytorch2onnx"></a>pytorch2onnx</h1><p>最近做的项目需要把训练好的模型移植到移动端，安卓手机上，实验室选择了ncnn这个框架，所以我选择了pytoch2onnx2ncnn框架的这个思路。下面主要是记录一下pytorch转onnx模型的步骤和踩过的坑。</p>
<p><a href="https://github.com/onnx/onnx" target="_blank" rel="noopener">项目地址</a>ONNX 定义了一种可扩展的计算图模型、一系列内置的运算单元（OP）和标准数据类型。每一个计算流图都定义为由节点组成的列表，并构建有向无环图。其中每一个节点都有一个或多个输入与输出，每一个节点称之为一个 OP。这相当于一种通用的计算图，不同深度学习框架构建的计算图都能转化为它。</p>
<p>如下所示，目前 ONNX 已经支持大多数框架，使用这些框架构建的模型可以转换为通用的 ONNX 计算图和 OP。现阶段 ONNX 只支持推理，所以导入的模型都需要在原框架完成训练。</p>
<p><img src="1568009953188.png" alt="支持的框架"></p>
<h2 id="1、操作步骤"><a href="#1、操作步骤" class="headerlink" title="1、操作步骤"></a>1、操作步骤</h2><p>首先一般情况下torch本身就是支持onnx类型的模型输出的，所以一般情况下，根据如下的脚本，基本就可以输出onnx类型的模型文件。以下脚本主要分为这三大部分：加载模型和模型参数，给定一个确定的输入，保存输出onnx类型的文件，至于这三步的代码具体应该怎么写完全根据自己，只要这三大步都有。笔者转的模型是一个二分类的分割任务，具体代码如下，完整代码会考虑上传到github上面。</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> torch<span class="token punctuation">.</span>autograd <span class="token keyword">import</span> Variable
<span class="token keyword">import</span> six
<span class="token keyword">import</span> sys
sys<span class="token punctuation">.</span>path<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token string">'../../'</span><span class="token punctuation">)</span>
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">from</span> models<span class="token punctuation">.</span>resnet <span class="token keyword">import</span> <span class="token operator">*</span>
<span class="token keyword">from</span> utils<span class="token punctuation">.</span>helpers <span class="token keyword">import</span> prepare_img
<span class="token keyword">from</span> PIL <span class="token keyword">import</span> Image
has_cuda <span class="token operator">=</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 加载模型和参数 笔者这里的加载调用了其他函数，贴在下面了</span>
<span class="token comment" spellcheck="true"># Initialise models</span>
model_inits <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token string">'rf_lw50_voc'</span>   <span class="token punctuation">:</span> rf_lw50<span class="token punctuation">,</span> <span class="token comment" spellcheck="true"># key / constructor</span>
<span class="token punctuation">}</span>
n_classes<span class="token operator">=</span><span class="token number">2</span>
models <span class="token operator">=</span> dict<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> key<span class="token punctuation">,</span>fun <span class="token keyword">in</span> six<span class="token punctuation">.</span>iteritems<span class="token punctuation">(</span>model_inits<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># 这里调用的其实是def rf_lw50(num_classes, imagenet=False, pretrained=True, **kwargs)</span>
    net <span class="token operator">=</span> fun<span class="token punctuation">(</span>n_classes<span class="token punctuation">,</span> pretrained<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">.</span>eval<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">if</span> has_cuda<span class="token punctuation">:</span>
        net <span class="token operator">=</span> net<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>
    models<span class="token punctuation">[</span>key<span class="token punctuation">]</span> <span class="token operator">=</span> net
    model<span class="token operator">=</span>net
<span class="token comment" spellcheck="true">#给定一个确定的输入 实际上可以随机初始化一个和需要的尺寸一致的numpy</span>
img_path<span class="token operator">=</span><span class="token string">"/home/litchi/PycharmProjects/light-weight-refinenet/examples/imgs/blind/1110a.png"</span>
img <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>Image<span class="token punctuation">.</span>open<span class="token punctuation">(</span>img_path<span class="token punctuation">)</span><span class="token punctuation">)</span>
input <span class="token operator">=</span>  <span class="token punctuation">(</span>torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span>prepare_img<span class="token punctuation">(</span>img<span class="token punctuation">)</span><span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">[</span>None<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>float<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">if</span> has_cuda<span class="token punctuation">:</span>
    input <span class="token operator">=</span> input<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># onnx模型文件输出</span>
torch_out <span class="token operator">=</span> torch<span class="token punctuation">.</span>onnx<span class="token punctuation">.</span>_export<span class="token punctuation">(</span>model<span class="token punctuation">,</span> input<span class="token punctuation">,</span> <span class="token string">"lw50.onnx"</span><span class="token punctuation">,</span>export_params<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>下面是创建模型和加载模型参数的代码</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 创建模型</span>
<span class="token keyword">class</span> <span class="token class-name">ResNetLW</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> block<span class="token punctuation">,</span> layers<span class="token punctuation">,</span> num_classes<span class="token operator">=</span><span class="token number">21</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>inplanes <span class="token operator">=</span> <span class="token number">64</span>
        super<span class="token punctuation">(</span>ResNetLW<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>do <span class="token operator">=</span> nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>p<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">7</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>
                               bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>bn1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>relu <span class="token operator">=</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>maxpool <span class="token operator">=</span> nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>layer1 <span class="token operator">=</span> self<span class="token punctuation">.</span>_make_layer<span class="token punctuation">(</span>block<span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> layers<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>layer2 <span class="token operator">=</span> self<span class="token punctuation">.</span>_make_layer<span class="token punctuation">(</span>block<span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> layers<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>layer3 <span class="token operator">=</span> self<span class="token punctuation">.</span>_make_layer<span class="token punctuation">(</span>block<span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> layers<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>layer4 <span class="token operator">=</span> self<span class="token punctuation">.</span>_make_layer<span class="token punctuation">(</span>block<span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> layers<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>p_ims1d2_outl1_dimred <span class="token operator">=</span> conv1x1<span class="token punctuation">(</span><span class="token number">2048</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>mflow_conv_g1_pool <span class="token operator">=</span> self<span class="token punctuation">.</span>_make_crp<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>mflow_conv_g1_b3_joint_varout_dimred <span class="token operator">=</span> conv1x1<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>p_ims1d2_outl2_dimred <span class="token operator">=</span> conv1x1<span class="token punctuation">(</span><span class="token number">1024</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>adapt_stage2_b2_joint_varout_dimred <span class="token operator">=</span> conv1x1<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>mflow_conv_g2_pool <span class="token operator">=</span> self<span class="token punctuation">.</span>_make_crp<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>mflow_conv_g2_b3_joint_varout_dimred <span class="token operator">=</span> conv1x1<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>p_ims1d2_outl3_dimred <span class="token operator">=</span> conv1x1<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>adapt_stage3_b2_joint_varout_dimred <span class="token operator">=</span> conv1x1<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>mflow_conv_g3_pool <span class="token operator">=</span> self<span class="token punctuation">.</span>_make_crp<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>mflow_conv_g3_b3_joint_varout_dimred <span class="token operator">=</span> conv1x1<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>p_ims1d2_outl4_dimred <span class="token operator">=</span> conv1x1<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>adapt_stage4_b2_joint_varout_dimred <span class="token operator">=</span> conv1x1<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>mflow_conv_g4_pool <span class="token operator">=</span> self<span class="token punctuation">.</span>_make_crp<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>clf_conv <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> num_classes<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>
                                  padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">_make_crp</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_planes<span class="token punctuation">,</span> out_planes<span class="token punctuation">,</span> stages<span class="token punctuation">)</span><span class="token punctuation">:</span>
        layers <span class="token operator">=</span> <span class="token punctuation">[</span>CRPBlock<span class="token punctuation">(</span>in_planes<span class="token punctuation">,</span> out_planes<span class="token punctuation">,</span>stages<span class="token punctuation">)</span><span class="token punctuation">]</span>
        <span class="token keyword">return</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token operator">*</span>layers<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">_make_layer</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> block<span class="token punctuation">,</span> planes<span class="token punctuation">,</span> blocks<span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        downsample <span class="token operator">=</span> None
        <span class="token keyword">if</span> stride <span class="token operator">!=</span> <span class="token number">1</span> <span class="token operator">or</span> self<span class="token punctuation">.</span>inplanes <span class="token operator">!=</span> planes <span class="token operator">*</span> block<span class="token punctuation">.</span>expansion<span class="token punctuation">:</span>
            downsample <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
                nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>self<span class="token punctuation">.</span>inplanes<span class="token punctuation">,</span> planes <span class="token operator">*</span> block<span class="token punctuation">.</span>expansion<span class="token punctuation">,</span>
                          kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> stride<span class="token operator">=</span>stride<span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>planes <span class="token operator">*</span> block<span class="token punctuation">.</span>expansion<span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token punctuation">)</span>

        layers <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        layers<span class="token punctuation">.</span>append<span class="token punctuation">(</span>block<span class="token punctuation">(</span>self<span class="token punctuation">.</span>inplanes<span class="token punctuation">,</span> planes<span class="token punctuation">,</span> stride<span class="token punctuation">,</span> downsample<span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>inplanes <span class="token operator">=</span> planes <span class="token operator">*</span> block<span class="token punctuation">.</span>expansion
        <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> blocks<span class="token punctuation">)</span><span class="token punctuation">:</span>
            layers<span class="token punctuation">.</span>append<span class="token punctuation">(</span>block<span class="token punctuation">(</span>self<span class="token punctuation">.</span>inplanes<span class="token punctuation">,</span> planes<span class="token punctuation">)</span><span class="token punctuation">)</span>

        <span class="token keyword">return</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token operator">*</span>layers<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>bn1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>maxpool<span class="token punctuation">(</span>x<span class="token punctuation">)</span>

        l1 <span class="token operator">=</span> self<span class="token punctuation">.</span>layer1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        l2 <span class="token operator">=</span> self<span class="token punctuation">.</span>layer2<span class="token punctuation">(</span>l1<span class="token punctuation">)</span>
        l3 <span class="token operator">=</span> self<span class="token punctuation">.</span>layer3<span class="token punctuation">(</span>l2<span class="token punctuation">)</span>
        l4 <span class="token operator">=</span> self<span class="token punctuation">.</span>layer4<span class="token punctuation">(</span>l3<span class="token punctuation">)</span>

        l4 <span class="token operator">=</span> self<span class="token punctuation">.</span>do<span class="token punctuation">(</span>l4<span class="token punctuation">)</span>
        l3 <span class="token operator">=</span> self<span class="token punctuation">.</span>do<span class="token punctuation">(</span>l3<span class="token punctuation">)</span>

        x4 <span class="token operator">=</span> self<span class="token punctuation">.</span>p_ims1d2_outl1_dimred<span class="token punctuation">(</span>l4<span class="token punctuation">)</span>
        x4 <span class="token operator">=</span> self<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>x4<span class="token punctuation">)</span>
        x4 <span class="token operator">=</span> self<span class="token punctuation">.</span>mflow_conv_g1_pool<span class="token punctuation">(</span>x4<span class="token punctuation">)</span>
        x4 <span class="token operator">=</span> self<span class="token punctuation">.</span>mflow_conv_g1_b3_joint_varout_dimred<span class="token punctuation">(</span>x4<span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true"># </span>
        <span class="token comment" spellcheck="true">#x4=F.interpolate(x4,size=l3.size()[2:],mode='bilinear',align_corners=True)</span>
        <span class="token comment" spellcheck="true">#x4 = nn.Upsample(size=l3.size()[2:], mode='bilinear', align_corners=False)(x4) #[60,34]</span>
        x4 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Upsample<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">60</span><span class="token punctuation">,</span><span class="token number">34</span><span class="token punctuation">]</span><span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">'bilinear'</span><span class="token punctuation">,</span> align_corners<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x4<span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">(</span>l3<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>


        x3 <span class="token operator">=</span> self<span class="token punctuation">.</span>p_ims1d2_outl2_dimred<span class="token punctuation">(</span>l3<span class="token punctuation">)</span>
        x3 <span class="token operator">=</span> self<span class="token punctuation">.</span>adapt_stage2_b2_joint_varout_dimred<span class="token punctuation">(</span>x3<span class="token punctuation">)</span>
        x3 <span class="token operator">=</span> x3 <span class="token operator">+</span> x4
        x3 <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>x3<span class="token punctuation">)</span>
        x3 <span class="token operator">=</span> self<span class="token punctuation">.</span>mflow_conv_g2_pool<span class="token punctuation">(</span>x3<span class="token punctuation">)</span>
        x3 <span class="token operator">=</span> self<span class="token punctuation">.</span>mflow_conv_g2_b3_joint_varout_dimred<span class="token punctuation">(</span>x3<span class="token punctuation">)</span>
       <span class="token comment" spellcheck="true"># x3 = F.interpolate(x3,size=l2.size()[2:],mode='bilinear',align_corners=True)</span>
       <span class="token comment" spellcheck="true"># x3 = nn.Upsample(size=l2.size()[2:], mode='bilinear', align_corners=False)(x3)</span>
        x3 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Upsample<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">120</span><span class="token punctuation">,</span><span class="token number">68</span><span class="token punctuation">]</span><span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">'bilinear'</span><span class="token punctuation">,</span> align_corners<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x3<span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">(</span>l2<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

        x2 <span class="token operator">=</span> self<span class="token punctuation">.</span>p_ims1d2_outl3_dimred<span class="token punctuation">(</span>l2<span class="token punctuation">)</span>
        x2 <span class="token operator">=</span> self<span class="token punctuation">.</span>adapt_stage3_b2_joint_varout_dimred<span class="token punctuation">(</span>x2<span class="token punctuation">)</span>
        x2 <span class="token operator">=</span> x2 <span class="token operator">+</span> x3
        x2 <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>x2<span class="token punctuation">)</span>
        x2 <span class="token operator">=</span> self<span class="token punctuation">.</span>mflow_conv_g3_pool<span class="token punctuation">(</span>x2<span class="token punctuation">)</span>
        x2 <span class="token operator">=</span> self<span class="token punctuation">.</span>mflow_conv_g3_b3_joint_varout_dimred<span class="token punctuation">(</span>x2<span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true">#x2 = nn.Upsample(size=l1.size()[2:], mode='bilinear', align_corners=False)(x2)</span>
        <span class="token comment" spellcheck="true">#x2=F.interpolate(x2,size=l1.size()[2:],mode='bilinear',align_corners=True)</span>
        x2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Upsample<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">240</span><span class="token punctuation">,</span><span class="token number">135</span><span class="token punctuation">]</span><span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">'bilinear'</span><span class="token punctuation">,</span> align_corners<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x2<span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">(</span>l1<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        x1 <span class="token operator">=</span> self<span class="token punctuation">.</span>p_ims1d2_outl4_dimred<span class="token punctuation">(</span>l1<span class="token punctuation">)</span>
        x1 <span class="token operator">=</span> self<span class="token punctuation">.</span>adapt_stage4_b2_joint_varout_dimred<span class="token punctuation">(</span>x1<span class="token punctuation">)</span>
        x1 <span class="token operator">=</span> x1 <span class="token operator">+</span> x2
        x1 <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>x1<span class="token punctuation">)</span>
        x1 <span class="token operator">=</span> self<span class="token punctuation">.</span>mflow_conv_g4_pool<span class="token punctuation">(</span>x1<span class="token punctuation">)</span>

        out <span class="token operator">=</span> self<span class="token punctuation">.</span>clf_conv<span class="token punctuation">(</span>x1<span class="token punctuation">)</span>
        <span class="token keyword">return</span> out

<span class="token keyword">def</span> <span class="token function">rf_lw50</span><span class="token punctuation">(</span>num_classes<span class="token punctuation">,</span> imagenet<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> pretrained<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># 创建了模型</span>
    model <span class="token operator">=</span> ResNetLW<span class="token punctuation">(</span>Bottleneck<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> num_classes<span class="token operator">=</span>num_classes<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># 加载模型参数,模型参数文件为./src/ckpt/checkpoint.pth.tar</span>
    <span class="token keyword">if</span> imagenet<span class="token punctuation">:</span>
        key <span class="token operator">=</span> <span class="token string">'50_imagenet'</span>
        url <span class="token operator">=</span> models_urls<span class="token punctuation">[</span>key<span class="token punctuation">]</span>
        model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>maybe_download<span class="token punctuation">(</span>key<span class="token punctuation">,</span> url<span class="token punctuation">)</span><span class="token punctuation">,</span> strict<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
    <span class="token keyword">elif</span> pretrained<span class="token punctuation">:</span>
        dataset <span class="token operator">=</span> data_info<span class="token punctuation">.</span>get<span class="token punctuation">(</span>num_classes<span class="token punctuation">,</span> None<span class="token punctuation">)</span>
        <span class="token keyword">if</span> dataset<span class="token operator">==</span><span class="token string">'blind'</span><span class="token punctuation">:</span>
            data<span class="token operator">=</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">'./src/ckpt/checkpoint.pth.tar'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token string">'segmenter'</span><span class="token punctuation">]</span>
            newdata<span class="token operator">=</span><span class="token punctuation">{</span><span class="token punctuation">}</span>
            <span class="token keyword">for</span> key <span class="token keyword">in</span> data<span class="token punctuation">:</span>
                newdata<span class="token punctuation">[</span>key<span class="token punctuation">[</span><span class="token number">7</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token operator">=</span>data<span class="token punctuation">[</span>key<span class="token punctuation">]</span>
            model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>newdata<span class="token punctuation">,</span>strict<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        <span class="token keyword">elif</span> dataset<span class="token punctuation">:</span>
            bname <span class="token operator">=</span> <span class="token string">'50_'</span> <span class="token operator">+</span> dataset<span class="token punctuation">.</span>lower<span class="token punctuation">(</span><span class="token punctuation">)</span>
            key <span class="token operator">=</span> <span class="token string">'rf_lw'</span> <span class="token operator">+</span> bname
            url <span class="token operator">=</span> models_urls<span class="token punctuation">[</span>bname<span class="token punctuation">]</span>
            model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>maybe_download<span class="token punctuation">(</span>key<span class="token punctuation">,</span> url<span class="token punctuation">)</span><span class="token punctuation">,</span> strict<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> model
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="2、添加操作符号"><a href="#2、添加操作符号" class="headerlink" title="2、添加操作符号"></a>2、添加操作符号</h2><p>在模型转换的过程中，可能遇到的一个问题是，在pytorch模型中存在的一个操作在onnx中可能不支持，所以我们就需要在onnx的源码中添加这个操作符的运算。其实详细的说明在torch的官方文档中都有。<a href="https://pytorch-cn.readthedocs.io/zh/latest/package_references/torch/" target="_blank" rel="noopener">torch中文官方文档</a>可以搜索onnx来看相关知识和用法。</p>
<p>以下是onnx模型一定支持的一些操作：</p>
<pre class="line-numbers language-python"><code class="language-python">add <span class="token punctuation">(</span>nonzero alpha <span class="token operator">not</span> supported<span class="token punctuation">)</span>
sub <span class="token punctuation">(</span>nonzero alpha <span class="token operator">not</span> supported<span class="token punctuation">)</span>
mul
div
cat
mm
addmm
neg
sqrt
tanh
sigmoid
mean
sum
prod
t
expand <span class="token punctuation">(</span>only when used before a broadcasting ONNX operator<span class="token punctuation">;</span> e<span class="token punctuation">.</span>g<span class="token punctuation">.</span><span class="token punctuation">,</span> add<span class="token punctuation">)</span>
transpose
view
split
squeeze
prelu <span class="token punctuation">(</span>single weight shared among input channels <span class="token operator">not</span> supported<span class="token punctuation">)</span>
threshold <span class="token punctuation">(</span>non<span class="token operator">-</span>zero threshold<span class="token operator">/</span>non<span class="token operator">-</span>zero value <span class="token operator">not</span> supported<span class="token punctuation">)</span>
leaky_relu
glu
softmax <span class="token punctuation">(</span>only dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span> supported<span class="token punctuation">)</span>
avg_pool2d <span class="token punctuation">(</span>ceil_mode <span class="token operator">not</span> supported<span class="token punctuation">)</span>
log_softmax
unfold <span class="token punctuation">(</span>experimental support <span class="token keyword">with</span> ATen<span class="token operator">-</span>Caffe2 integration<span class="token punctuation">)</span>
elu
concat
abs
index_select
pow
clamp
max
min
eq
gt
lt
ge
le
exp
sin
cos
tan
asin
acos
atan
permute
Conv
BatchNorm
MaxPool1d <span class="token punctuation">(</span>ceil_mode <span class="token operator">not</span> supported<span class="token punctuation">)</span>
MaxPool2d <span class="token punctuation">(</span>ceil_mode <span class="token operator">not</span> supported<span class="token punctuation">)</span>
MaxPool3d <span class="token punctuation">(</span>ceil_mode <span class="token operator">not</span> supported<span class="token punctuation">)</span>
Embedding <span class="token punctuation">(</span>no optional arguments supported<span class="token punctuation">)</span>
RNN
ConstantPadNd
Dropout
FeatureDropout <span class="token punctuation">(</span>training mode <span class="token operator">not</span> supported<span class="token punctuation">)</span>
Index <span class="token punctuation">(</span>constant integer <span class="token operator">and</span> tuple indices supported<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>具体的实现过程可以在torch.onnx.symbolic.py中查看，这里有一句_onnx_opset_version = 6，此外还有8,9等差别可以自己查询一下。笔者这里贴出其中两个来举例子：</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">add</span><span class="token punctuation">(</span>g<span class="token punctuation">,</span> self<span class="token punctuation">,</span> other<span class="token punctuation">,</span> alpha<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">if</span> _scalar<span class="token punctuation">(</span>alpha<span class="token punctuation">)</span> <span class="token operator">!=</span> <span class="token number">1</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> _unimplemented<span class="token punctuation">(</span><span class="token string">"add"</span><span class="token punctuation">,</span> <span class="token string">"alpha != 1"</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># See Note [Pointwise by scalar]</span>
    <span class="token keyword">return</span> g<span class="token punctuation">.</span>op<span class="token punctuation">(</span><span class="token string">"Add"</span><span class="token punctuation">,</span> self<span class="token punctuation">,</span> _if_scalar_type_as<span class="token punctuation">(</span>other<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">**</span>_broadcast_if_scalar<span class="token punctuation">(</span>other<span class="token punctuation">)</span><span class="token punctuation">)</span>


<span class="token keyword">def</span> <span class="token function">sub</span><span class="token punctuation">(</span>g<span class="token punctuation">,</span> self<span class="token punctuation">,</span> other<span class="token punctuation">,</span> alpha<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">if</span> _scalar<span class="token punctuation">(</span>alpha<span class="token punctuation">)</span> <span class="token operator">!=</span> <span class="token number">1</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> _unimplemented<span class="token punctuation">(</span><span class="token string">"sub"</span><span class="token punctuation">,</span> <span class="token string">"alpha != 1"</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># See Note [Pointwise by scalar]</span>
    <span class="token keyword">return</span> g<span class="token punctuation">.</span>op<span class="token punctuation">(</span><span class="token string">"Sub"</span><span class="token punctuation">,</span> self<span class="token punctuation">,</span> _if_scalar_type_as<span class="token punctuation">(</span>other<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">**</span>_broadcast_if_scalar<span class="token punctuation">(</span>other<span class="token punctuation">)</span><span class="token punctuation">)</span>


<span class="token keyword">def</span> <span class="token function">mul</span><span class="token punctuation">(</span>g<span class="token punctuation">,</span> self<span class="token punctuation">,</span> other<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># See Note [Pointwise by scalar]</span>
    <span class="token keyword">return</span> g<span class="token punctuation">.</span>op<span class="token punctuation">(</span><span class="token string">"Mul"</span><span class="token punctuation">,</span> self<span class="token punctuation">,</span> _if_scalar_type_as<span class="token punctuation">(</span>other<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">**</span>_broadcast_if_scalar<span class="token punctuation">(</span>other<span class="token punctuation">)</span><span class="token punctuation">)</span>


<span class="token keyword">def</span> <span class="token function">div</span><span class="token punctuation">(</span>g<span class="token punctuation">,</span> self<span class="token punctuation">,</span> other<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># See Note [Pointwise by scalar]</span>
    <span class="token keyword">return</span> g<span class="token punctuation">.</span>op<span class="token punctuation">(</span><span class="token string">"Div"</span><span class="token punctuation">,</span> self<span class="token punctuation">,</span> _if_scalar_type_as<span class="token punctuation">(</span>other<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">**</span>_broadcast_if_scalar<span class="token punctuation">(</span>other<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>以上分别是加减乘除运算的实现过程，所以加入自己要自定义操作符号，也应该仿照如上的运算符进行实现。</p>
<p>添加的时候也分为两种情况，一种是在Aten中存在的运算符，一种是没有的。</p>
<h3 id="2-1在Aten中有的运算符"><a href="#2-1在Aten中有的运算符" class="headerlink" title="2.1在Aten中有的运算符"></a>2.1在Aten中有的运算符</h3><p>如果增加的operation可以用ATen operation(ATen是pyTorch底层调用的C++ 11库，由pytorch团队开发的)实现，则可以在torch/csrc/autograd/generated/VariableType.h中找到他的声明，在torch/onnx/symbolic.py中添加它，按以下步骤：</p>
<ol>
<li>在torch/onnx/symbolic.py中定义声明函数，确保函数名与在头文件中VariableType.h的ATen operation的函数名一样.</li>
<li>函数中的第一个参数必须为ONNX模型图，如add operation的函数名def add(g, self, other, alpha):第一个参数必须是g，其他参数名必须同VariableType.h完全一致. </li>
<li>参数的顺序没有强制性要求，一般input参数为张量类型，然后是其他参数为非张量参数.<br>如果输入参数是张量，但是ONNX要求标量，我们必须明确地进行转换。 辅助函数_scalar可以将标量张量转换为python标量，_if_scalar_type_as可以将Python标量转换为PyTorch张量</li>
</ol>
<p>在笔者的这个模型的转换中，由于这是一个分割项目，所以一定有上采样升高图片的分辨率的这样的一个过程，所以就涉及到了插值，我需要补充的是双线性插值。代码如下</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">upsample_bilinear2d</span><span class="token punctuation">(</span>g<span class="token punctuation">,</span> input<span class="token punctuation">,</span> output_size<span class="token punctuation">,</span> align_corners<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">if</span> align_corners<span class="token punctuation">:</span>
        <span class="token keyword">return</span> _unimplemented<span class="token punctuation">(</span><span class="token string">"upsample_bilinear2d"</span><span class="token punctuation">,</span> <span class="token string">"align_corners == True"</span><span class="token punctuation">)</span>
    height_scale <span class="token operator">=</span> float<span class="token punctuation">(</span>output_size<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">/</span> input<span class="token punctuation">.</span>type<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>sizes<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">]</span>
    width_scale <span class="token operator">=</span> float<span class="token punctuation">(</span>output_size<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">/</span> input<span class="token punctuation">.</span>type<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>sizes<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>
    scales <span class="token operator">=</span> g<span class="token punctuation">.</span>op<span class="token punctuation">(</span><span class="token string">"Constant"</span><span class="token punctuation">,</span> value_t<span class="token operator">=</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> height_scale<span class="token punctuation">,</span>
                                                    width_scale<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> g<span class="token punctuation">.</span>op<span class="token punctuation">(</span><span class="token string">"Upsample"</span><span class="token punctuation">,</span> input<span class="token punctuation">,</span> scales<span class="token punctuation">,</span>
                mode_s<span class="token operator">=</span><span class="token string">"linear"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>同理，最近邻插值可以重写为:</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">upsample_nearest2d</span><span class="token punctuation">(</span>g<span class="token punctuation">,</span> input<span class="token punctuation">,</span> output_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
    height_scale <span class="token operator">=</span> float<span class="token punctuation">(</span>output_size<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">/</span> input<span class="token punctuation">.</span>type<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>sizes<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">]</span>
    width_scale <span class="token operator">=</span> float<span class="token punctuation">(</span>output_size<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">/</span> input<span class="token punctuation">.</span>type<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>sizes<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>
    <span class="token keyword">return</span> g<span class="token punctuation">.</span>op<span class="token punctuation">(</span><span class="token string">"Upsample"</span><span class="token punctuation">,</span> input<span class="token punctuation">,</span>
                scales_f<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> height_scale<span class="token punctuation">,</span> width_scale<span class="token punctuation">)</span><span class="token punctuation">,</span>
                mode_s<span class="token operator">=</span><span class="token string">"nearest"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="2-2-在Aten中没有的运算符"><a href="#2-2-在Aten中没有的运算符" class="headerlink" title="2.2 在Aten中没有的运算符"></a>2.2 在Aten中没有的运算符</h3><p>如果增加的operation不能用ATen库实现，则需要在相关的pyTorch Function 类中添加声明函数，操作如下：</p>
<ol>
<li><p>在相关的Function类中创建一个函数，如命名为symbolic.</p>
</li>
<li><p>同样的第一个参数必须是ONNX图g.</p>
</li>
<li><p>其他参数命名必须与forward中的名字一致.</p>
</li>
<li><p>输出的tuple大小必须与forward的输出大小一致.</p>
</li>
<li><p>声明函数应该使用python定义，方法的具体实现使用C++-Python绑定实现，具体接口如下：</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> operator<span class="token operator">/</span>symbolic<span class="token punctuation">(</span>g<span class="token punctuation">,</span> <span class="token operator">*</span>inputs<span class="token punctuation">)</span><span class="token punctuation">:</span>
  <span class="token triple-quoted-string string">"""
  Modifies Graph (e.g., using "op"), adding the ONNX operations representing
  this PyTorch function, and returning a Value or tuple of Values specifying the
  ONNX outputs whose values correspond to the original PyTorch return values
  of the autograd Function (or None if an output is not supported by ONNX).

  Arguments:
    g (Graph): graph to write the ONNX representation into
    inputs (Value...): list of values representing the variables which contain
        the inputs for this function
  """</span>

<span class="token keyword">class</span> <span class="token class-name">Value</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>
  <span class="token triple-quoted-string string">"""Represents an intermediate tensor value computed in ONNX."""</span>
  <span class="token keyword">def</span> <span class="token function">type</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""Returns the Type of the value."""</span>

<span class="token keyword">class</span> <span class="token class-name">Type</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>
  <span class="token keyword">def</span> <span class="token function">sizes</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""Returns a tuple of ints representing the shape of a tensor this describes."""</span>

<span class="token keyword">class</span> <span class="token class-name">Graph</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>
  <span class="token keyword">def</span> <span class="token function">op</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> opname<span class="token punctuation">,</span> <span class="token operator">*</span>inputs<span class="token punctuation">,</span> <span class="token operator">**</span>attrs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    Create an ONNX operator 'opname', taking 'args' as inputs
    and attributes 'kwargs' and add it as a node to the current graph,
    returning the value representing the single output of this
    operator (see the `outputs` keyword argument for multi-return
    nodes).

    The set of operators and the inputs/attributes they take
    is documented at https://github.com/onnx/onnx/blob/master/docs/Operators.md

    Arguments:
        opname (string): The ONNX operator name, e.g., `Abs` or `Add`.
        args (Value...): The inputs to the operator; usually provided
            as arguments to the `symbolic` definition.
        kwargs: The attributes of the ONNX operator, with keys named
            according to the following convention: `alpha_f` indicates
            the `alpha` attribute with type `f`.  The valid type specifiers are
            `f` (float), `i` (int), `s` (string) or `t` (Tensor).  An attribute
            specified with type float accepts either a single float, or a
            list of floats (e.g., you would say `dims_i` for a `dims` attribute
            that takes a list of integers).
        outputs (int, optional):  The number of outputs this operator returns;
            by default an operator is assumed to return a single output.
            If `outputs` is greater than one, this functions returns a tuple
            of output `Value`, representing each output of the ONNX operator
            in positional.
    """</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
</li>
</ol>
<h2 id="3、动态图的尺寸"><a href="#3、动态图的尺寸" class="headerlink" title="3、动态图的尺寸"></a>3、动态图的尺寸</h2><p>由于pytorch是动态图，所以就算是在onnx的源码中添加了运算符操作之后，也可能出现问题，问题就是不知道input的尺寸（当创建模型的时候input尺寸是可变的的话）所以也可以看看笔者上边的创建模型的代码，在def forward(self, x)这个函数中，笔者将原来的 x4 = nn.Upsample(size=l3.size()[2:], mode=’bilinear’, align_corners=False)(x4)注释掉了，而是写成了 x4 = nn.Upsample(size=[60,34], mode=’bilinear’, align_corners=False)(x4)，这样子就是把input的尺寸写死了。所以在调用ncnn模型进行前向传播的时候也要注意在将图片输入网络之前一定要将尺寸处理为与模型中的尺寸一致。</p>
<p>完成如上操作确定没错，运行在第一部分提到的脚本，可以生成一个lw50.onnx文件</p>
<p><img src="1568013888302.png" alt="生成模型"></p>

            </div>
            <hr />

            
            <style>
    #reward {
        margin: 40px 0;
        text-align: center;
    }

    #reward .reward-link {
        font-size: 1.88rem;
    }

    #reward .btn-floating:hover {
        box-shadow: 0 6px 12px rgba(0, 0, 0, 0.2), 0 5px 15px rgba(0, 0, 0, 0.2);
    }

    #rewardModal {
        width: 320px;
        height: 350px;
    }

    #rewardModal .reward-title {
        margin: 15px auto;
        padding-bottom: 5px;
    }

    #rewardModal .modal-content {
        padding: 10px;
    }

    #rewardModal .close {
        position: absolute;
        right: 15px;
        top: 15px;
        color: rgba(0, 0, 0, 0.5);
        font-size: 1.3rem;
        line-height: 20px;
        cursor: pointer;
    }

    #rewardModal .close:hover {
        color: #ef5350;
        transform: scale(1.3);
        -moz-transform:scale(1.3);
        -webkit-transform:scale(1.3);
        -o-transform:scale(1.3);
    }

    #rewardModal .reward-tabs {
        margin: 0 auto;
        width: 210px;
    }

    .reward-tabs .tabs {
        height: 38px;
        margin: 10px auto;
        padding-left: 0;
    }

    .reward-content ul {
        padding-left: 0 !important;
    }

    .reward-tabs .tabs .tab {
        height: 38px;
        line-height: 38px;
    }

    .reward-tabs .tab a {
        color: #fff;
        background-color: #ccc;
    }

    .reward-tabs .tab a:hover {
        background-color: #ccc;
        color: #fff;
    }

    .reward-tabs .wechat-tab .active {
        color: #fff !important;
        background-color: #22AB38 !important;
    }

    .reward-tabs .alipay-tab .active {
        color: #fff !important;
        background-color: #019FE8 !important;
    }

    .reward-tabs .reward-img {
        width: 210px;
        height: 210px;
    }
</style>

<div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-large waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fa fa-close"></i></a>
            <h4 class="reward-title">能否打赏一杯咖啡，让我有继续写作的动力？</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                        <li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="/medias/reward/alipay.jpg" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                    <div id="wechat">
                        <img src="/medias/reward/wechat.png" class="reward-img" alt="微信打赏二维码">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>
            

            <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">

<div id="article-share">
    
    <div class="social-share" data-disabled="qzone" data-wechat-qrcode-helper="<p>微信里点“发现”->“扫一扫”二维码便可查看分享。</p>"></div>
    
</div>

<script src="/libs/share/js/social-share.min.js"></script>

            

    <div class="reprint" id="reprint-statement">
        <p class="reprint-tip">
            <i class="fa fa-exclamation-triangle"></i>&nbsp;&nbsp;
            <span>转载规则</span>
        </p>
        
            <div class="center-align">
                <a rel="license" href="https://creativecommons.org/licenses/by/4.0/deed.zh">
                    <img alt=""
                         style="border-width:0"
                         src="https://i.creativecommons.org/l/by/4.0/88x31.png"/>
                </a>
            </div>
            <br/>
            <span xmlns:dct="http://purl.org/dc/terms/" href="http://purl.org/dc/dcmitype/Text"
                  property="dct:title" rel="dct:type">
                    《pytorch2onnx》
                </span> 由
            <a xmlns:cc="http://creativecommons.org/ns#" href="/2019/09/09/pytorch2onnx/" property="cc:attributionName"
               rel="cc:attributionURL">
                ivory
            </a> 采用
            <a rel="license" href="https://creativecommons.org/licenses/by/4.0/deed.zh">
                知识共享署名 4.0 国际许可协议
            </a>进行许可。
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>


        </div>
    </div>

    
    <link rel="stylesheet" href="/libs/gitalk/gitalk.css">
<link rel="stylesheet" href="/css/my-gitalk.css">

<div class="card gitalk-card" data-aos="fade-up">
    <div id="gitalk-container" class="card-content"></div>
</div>

<script src="/libs/gitalk/gitalk.min.js"></script>
<script>
    let gitalk = new Gitalk({
        clientID: '',
        clientSecret: '',
        repo: 'yyingbiu.github.io',
        owner: 'yyingcute',
        admin: "yyingcute",
        id: '2019/09/09/pytorch2onnx/',
        distractionFreeMode: false  // Facebook-like distraction free mode
    });

    gitalk.render('gitalk-container');
</script>
    

    
    <link rel="stylesheet" href="/libs/gitment/gitment-default.css">
<link rel="stylesheet" href="/css/gitment.css">

<div class="gitment-card card" data-aos="fade-up">
    <div id="gitment-content" class="card-content"></div>
</div>

<script src="/libs/gitment/gitment.js"></script>
<script>
var gitment = new Gitment({
    id: 'Mon Sep 09 2019 15:26:03 GMT+0800',
    owner: '',
    repo: '',
    oauth: {
        client_id: '',
        client_secret: ''
    }
});

gitment.render('gitment-content');
</script>
    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fa fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/2019/09/09/onnx2ncnn-bing-zai-pc-duan-diao-yong-ncnn-mo-xing/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/0.png" class="responsive-img" alt="onnx2ncnn并在pc端调用ncnn模型">
                        
                        <span class="card-title">onnx2ncnn并在pc端调用ncnn模型</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            onnx2ncnn并在pc端调用ncnn模型1、编译安装ncnn首先应该在电脑上编译安装ncnn，配置安装过程可以参考笔者的这篇博文Linux下编译安装NCNN
2、确保已经转换好onnx模型pytorch转onnx模型可以参考笔者的这篇 
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="fa fa-clock-o fa-fw icon-date"></i>2019-09-09
                        </span>
                        <span class="publish-author">
                            
                            <i class="fa fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/深度学习框架/" class="post-category" target="_blank">
                                    深度学习框架
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/onnx/" target="_blank">
                        <span class="chip bg-color">onnx</span>
                    </a>
                    
                    <a href="/tags/ncnn/" target="_blank">
                        <span class="chip bg-color">ncnn</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fa fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/2019/09/08/kai-xue-sui-ji/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/7.png" class="responsive-img" alt="开学随记">
                        
                        <span class="card-title">开学随记</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            开学随记因为最近发生一些事，和从小一起长大的朋友进行了一次促膝长叹，一直觉得她三观正，这次我终于能静下心认真把她的一些话听进去了。可能因为家庭氛围原因，我一直以来过得比较自我，确实是共情能力较差，到现在为止很多关系也处理的不好，也从没有觉得
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="fa fa-clock-o fa-fw icon-date"></i>2019-09-08
                            </span>
                        <span class="publish-author">
                            
                            <i class="fa fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/随笔/" class="post-category" target="_blank">
                                    随笔
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/随笔/" target="_blank">
                        <span class="chip bg-color">随笔</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>
</div>


<script>
    $('#articleContent').on('copy', function (e) {
        // IE8 or earlier browser is 'undefined'
        if (typeof window.getSelection === 'undefined') return;

        var selection = window.getSelection();
        // if the selection is short let's not annoy our users.
        if (('' + selection).length < Number.parseInt('120')) {
            return;
        }

        // create a div outside of the visible area and fill it with the selected text.
        var bodyElement = document.getElementsByTagName('body')[0];
        var newdiv = document.createElement('div');
        newdiv.style.position = 'absolute';
        newdiv.style.left = '-99999px';
        bodyElement.appendChild(newdiv);
        newdiv.appendChild(selection.getRangeAt(0).cloneContents());

        // we need a <pre> tag workaround.
        // otherwise the text inside "pre" loses all the line breaks!
        if (selection.getRangeAt(0).commonAncestorContainer.nodeName === 'PRE') {
            newdiv.innerHTML = "<pre>" + newdiv.innerHTML + "</pre>";
        }

        var url = document.location.href;
        newdiv.innerHTML += '<br />'
            + '来源: ivory's blog<br />'
            + '作者: ivory<br />'
            + '链接: <a href="' + url + '">' + url + '</a><br />'
            + '本文章著作权归作者所有，任何形式的转载都请注明出处。';

        selection.selectAllChildren(newdiv);
        window.setTimeout(function () { bodyElement.removeChild(newdiv); }, 200);
    });
</script>

    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget">
            <div class="toc-title"><i class="fa fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fa fa-list"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            // headingsOffset: -205,
            headingSelector: 'h1, h2, h3, h4'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h1, h2, h3, h4').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).slideUp(500);
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).slideDown(500);
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>


<script src="https://cdn.bootcss.com/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script>
    MathJax.Hub.Config({
        tex2jax: {inlineMath: [['$', '$'], ['\(', '\)']]}
    });
</script>

<footer class="page-footer bg-color">
    <div class="container row center-align">
        <div class="col s12 m8 l8 copy-right">
            &copy; 2019 YingYang. All Rights Reserved.

            
            &nbsp;<i class="fa fa-area-chart"></i>&nbsp;站点总字数:&nbsp;
            <span class="white-color">40.9k</span>
            

            <br>
            <span id="sitetime"></span>

            
            
        </div>
        <div class="col s12 m4 l4 social-link ">
    <a href="https://github.com/yyingbiu" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fa fa-github"></i>
    </a>



    <a href="mailto:ivory.yang.ying@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fa fa-envelope-open"></i>
    </a>





    <a href="https://user.qzone.qq.com/709585389" class="tooltipped" target="_blank" data-tooltip="访问我的QQ空间" data-position="top" data-delay="50">
        <i class="fa fa-qq"></i>
    </a>



    <a href="https://weibo.com/3190474980" class="tooltipped" target="_blank" data-tooltip="关注我的微博" data-position="top" data-delay="50">
        <i class="fa fa-weibo"></i>
    </a>



    <a href="/atom.xml" class="tooltipped" target="_blank" data-tooltip="RSS 订阅" data-position="top" data-delay="50">
        <i class="fa fa-rss"></i>
    </a>
</div>
    </div>
</footer>

<div class="progress-bar"></div>

<!-- 不蒜子计数初始值纠正 -->
<script>
    $(document).ready(function () {

        var int = setInterval(fixCount, 50);
        var pvcountOffset = 80000;
        var uvcountOffset = 20000;

        function fixCount() {
            if (document.getElementById("busuanzi_container_site_pv").style.display != "none") {
                $("#busuanzi_value_site_pv").html(parseInt($("#busuanzi_value_site_pv").html()) + pvcountOffset);
                clearInterval(int);
            }
            if ($("#busuanzi_container_site_pv").css("display") != "none") {
                $("#busuanzi_value_site_uv").html(parseInt($("#busuanzi_value_site_uv").html()) + uvcountOffset); // 加上初始数据 
                clearInterval(int);
            }
        }
    });
</script>

<script language=javascript>
    function siteTime() {
        window.setTimeout("siteTime()", 1000);
        var seconds = 1000;
        var minutes = seconds * 60;
        var hours = minutes * 60;
        var days = hours * 24;
        var years = days * 365;
        var today = new Date();
        var todayYear = today.getFullYear();
        var todayMonth = today.getMonth() + 1;
        var todayDate = today.getDate();
        var todayHour = today.getHours();
        var todayMinute = today.getMinutes();
        var todaySecond = today.getSeconds();
        /* Date.UTC() -- 返回date对象距世界标准时间(UTC)1970年1月1日午夜之间的毫秒数(时间戳)
        year - 作为date对象的年份，为4位年份值
        month - 0-11之间的整数，做为date对象的月份
        day - 1-31之间的整数，做为date对象的天数
        hours - 0(午夜24点)-23之间的整数，做为date对象的小时数
        minutes - 0-59之间的整数，做为date对象的分钟数
        seconds - 0-59之间的整数，做为date对象的秒数
        microseconds - 0-999之间的整数，做为date对象的毫秒数 */
        var t1 = Date.UTC(2019, 07, 11, 00, 00, 00); //北京时间2018-2-13 00:00:00
        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
        var diff = t2 - t1;
        var diffYears = Math.floor(diff / years);
        var diffDays = Math.floor((diff / days) - diffYears * 365);
        var diffHours = Math.floor((diff - (diffYears * 365 + diffDays) * days) / hours);
        var diffMinutes = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours) / minutes);
        var diffSeconds = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours - diffMinutes * minutes) / seconds);
        document.getElementById("sitetime").innerHTML = "本站已运行 " + diffYears + " 年 " + diffDays + " 天 " + diffHours + " 小时 " + diffMinutes + " 分钟 " + diffSeconds + " 秒";
    }/*因为建站时间还没有一年，就将之注释掉了。需要的可以取消*/
    siteTime();
</script>


<!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fa fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script src="/js/search.js"></script>
<script type="text/javascript">
$(function () {
    searchFunc("/" + "search.xml", 'searchInput', 'searchResult');
});
</script>
<!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fa fa-angle-up"></i>
    </a>
</div>


<script src="/libs/materialize/materialize.min.js"></script>
<script src="/libs/masonry/masonry.pkgd.min.js"></script>
<script src="/libs/aos/aos.js"></script>
<script src="/libs/scrollprogress/scrollProgress.min.js"></script>
<script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
<script src="/js/matery.js"></script>

<!-- Global site tag (gtag.js) - Google Analytics -->

<script async src="https://www.googletagmanager.com/gtag/js?id="></script>
<script>
    window.dataLayer = window.dataLayer || [];
    function gtag() {
        dataLayer.push(arguments);
    }

    gtag('js', new Date());
    gtag('config', '');
</script>





</body>
</html>